---
title: "Tutorial 1"
output:
  md_document:
    variant: markdown_github
    toc: false
    pandoc_args: ["--extract-media", "docs/assets/images"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(arrow)
require(data.table)
require(knitr)
```

# Data

Per questa serie di tutorial, useremo l'__Emotions Dataset__, un classico esempio di _Supervised Classification_. 
Curato da [Hari Shankar](https://www.linkedin.com/in/this-is-hari-shankar/) e disponibile sulla piattaforma [Hugging Face](https://huggingface.co/datasets/boltuix/emotions-dataset). 
Viene rilasciato con licenza MIT. 

Il dataset è composto da una collezione di 131.306 frasi in lingua inglese ("Sentence"). La lunghezza media di queste frasi è di circa 14 parole. A ogni frase è associata un'emozione ("Label"), per un totale di 13 categorie diverse, inclusa l'opzione "Neutral" per identificare l'assenza di emozioni specifiche.

Un aspetto fondamentale di questo dataset è che la distribuzione delle emozioni è sbilanciata. 
Ecco alcune delle categorie più frequenti:

```{r my_table, echo=FALSE}

tmp <- read_parquet('/home/dario/Downloads/Mahalanobis.io/code/emotions_dataset.parquet')
tmp <- as.data.table(tmp)
tmp <- tmp[,.N,by=.(Label)]
tmp <- tmp[order(-N)]
tmp[,Pct := N / sum(tmp$N)]
tmp[,Pct := paste0( sprintf("%.2f", Pct*100) ,"%") ]
names(tmp)[1] = "Emotion"
names(tmp)[3] = "%"
knitr::kable( head(tmp,5) , caption = "Emotions Distribution")

```

Le restanti categorie includono: Fear, Disgust, Confusion, Surprise, Shame, Guilt, Sarcasm e Desire. Ognuna di queste ha un numero di occorrenze variabile, significativamente inferiore rispetto alle prime cinque.

### Implicazioni 
Il buon senso ci suggerisce che questa distribuzione delle emozioni è quasi certamente il risultato del modo in cui il dataset è stato costruito, e non riflette la frequenza reale con cui le diverse emozioni vengono espresse nel linguaggio quotidiano.

Di conseguenza, dovremo tenere a mente due punti chiave:

Specificità del Dataset: Dobbiamo considerare la distribuzione delle classi come una caratteristica intrinseca di questo specifico dataset, non come una rappresentazione universale della probabilità delle emozioni.

Gestione dello Sbilanciamento: Sarà cruciale gestire attivamente questo sbilanciamento delle classi. Il nostro obiettivo non è "correggere" una distribuzione reale sconosciuta, ma piuttosto assicurarci che i nostri modelli abbiano abbastanza esempi per imparare efficacemente a riconoscere anche le categorie meno rappresentate, garantendo una buona capacità di generalizzazione in fase di inferenza. 
