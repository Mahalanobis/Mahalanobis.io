---
title: "Tutorial 1"
output:
  md_document:
    variant: markdown_github
    toc: true
    pandoc_args: ["--extract-media", "docs/assets/images"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data

Per questa serie di tutorial, useremo l'__Emotions Dataset__, un classico esempio di _Supervised Classification_. 
Curato da [Hari Shankar](https://www.linkedin.com/in/this-is-hari-shankar/) e disponibile sulla piattaforma [Hugging Face](https://huggingface.co/datasets/boltuix/emotions-dataset). 
Viene rilasciato con licenza MIT. 

## Struttura e Caratteristiche
Il dataset è composto da una collezione di 131.306 frasi in lingua inglese ("Sentence"). La lunghezza media di queste frasi è di circa 14 parole. A ogni frase è associata un'emozione ("Label"), per un totale di 13 categorie diverse, inclusa l'opzione "Neutral" per identificare l'assenza di emozioni specifiche.

## La Distribuzione delle Classi
Un aspetto fondamentale di questo dataset è che la distribuzione delle emozioni è sbilanciata. Ecco alcune delle categorie più frequenti:
Happiness: presente in 31.205 frasi (circa il 24% del totale).
Sadness: presente in 17.809 frasi (circa il 14%).
Neutral: presente in 15.733 frasi (circa il 12%).

Le restanti categorie includono: Anger, Love, Fear, Disgust, Confusion, Surprise, Shame, Guilt, Sarcasm e Desire. Ognuna di queste ha un numero di occorrenze variabile, significativamente inferiore rispetto alle prime tre.

### Implicazioni 
Il buon senso ci suggerisce che questa distribuzione delle emozioni è quasi certamente il risultato del modo in cui il dataset è stato costruito, e non riflette la frequenza reale con cui le diverse emozioni vengono espresse nel linguaggio quotidiano.

Di conseguenza, dovremo tenere a mente due punti chiave:

Specificità del Dataset: Dobbiamo considerare la distribuzione delle classi come una caratteristica intrinseca di questo specifico dataset, non come una rappresentazione universale della probabilità delle emozioni.

Gestione dello Sbilanciamento: Sarà cruciale gestire attivamente questo sbilanciamento delle classi. Il nostro obiettivo non è "correggere" una distribuzione reale sconosciuta, ma piuttosto assicurarci che i nostri modelli abbiano abbastanza esempi per imparare efficacemente a riconoscere anche le categorie meno rappresentate, garantendo una buona capacità di generalizzazione in fase di inferenza. 
