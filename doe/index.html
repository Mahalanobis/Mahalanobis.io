<!DOCTYPE html>
<html lang="en" data-bs-theme="light">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        <link rel="canonical" href="https://mahalanobis.github.io/Mahalanobis.io/doe/">
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>DoE - Fine-Tuning a small LLM (4Stats)</title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/fontawesome.min.css" rel="stylesheet">
        <link href="../css/brands.min.css" rel="stylesheet">
        <link href="../css/solid.min.css" rel="stylesheet">
        <link href="../css/v4-font-face.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link id="hljs-light" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/purebasic.min.css" >
        <link id="hljs-dark" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github-dark.min.css" disabled>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script>hljs.highlightAll();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="..">Fine-Tuning a small LLM (4Stats)</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar-collapse" aria-controls="navbar-collapse" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="nav-item">
                                <a href=".." class="nav-link">Intro</a>
                            </li>
                            <li class="nav-item">
                                <a href="./" class="nav-link active" aria-current="page">DoE</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ms-md-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-bs-toggle="modal" data-bs-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href=".." class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" class="nav-link disabled">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-bs-toggle="collapse" data-bs-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-body-tertiary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-bs-level="1"><a href="#doe" class="nav-link">DoE</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-bs-level="2"><a href="#perche-la-scelta-del-trainset-e-cruciale" class="nav-link">Perché la scelta del Trainset è cruciale?</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="1"><a href="#perche-gemma3" class="nav-link">Perchè Gemma3</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="1"><a href="#fine-tuning-a-small-llm" class="nav-link">Fine-tuning a small LLM</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-bs-level="2"><a href="#vram" class="nav-link">VRAM</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#training" class="nav-link">Training</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="doe">DoE</h1>
<p>Quando si parla di <strong>Design of Experiment (DoE)</strong>, di solito pensiamo a un metodo statistico per pianificare esperimenti. L'idea è semplice: vogliamo capire come diverse <em>variabili (o fattori)</em> influenzano un certo <em>risultato (o risposta)</em>, cercando di ottenere il massimo delle informazioni con il minor numero di prove e garantendo che i nostri risultati siano validi ed efficienti.</p>
<p>Tuttavia, nel contesto di questo tutorial, <em>il DoE assume una sfumatura un po' diversa</em>. Non stiamo progettando un esperimento per testare direttamente l'impatto di alcune variabili su un modello. Invece, stiamo applicando i principi del DoE per <em>definire con cura il dataset (il "trainset")</em> che useremo. Questo trainset sarà fondamentale per due scopi:</p>
<ul>
<li>
<p><strong>Addestrare i modelli di AI tradizionale.</strong></p>
</li>
<li>
<p><strong>Predisporre il fine-tuning di un Large Language Model (LLM).</strong></p>
</li>
</ul>
<p>Il nostro obiettivo qui è chiaro: selezionare un sottoinsieme di osservazioni che sia il più rappresentativo, bilanciato e informato possibile, massimizzando l'efficacia del fine-tuning.</p>
<h2 id="perche-la-scelta-del-trainset-e-cruciale">Perché la scelta del Trainset è cruciale?</h2>
<p>Il <span style="background-color: red;"><a href="https://github.com/Mahalanobis/Mahalanobis.io/blob/main/code/FT_Emotions_Dataset_DOE.py">codice</a></span> seleziona un trainset relativamente piccolo, appena 50.000 frasi. Questa non è una scelta casuale! Vogliamo esplorare un aspetto fondamentale della recente letteratura sugli LLM, che suggerisce come il fine-tuning di un modello pre-addestrato possa essere incredibilmente efficace anche con un numero limitato di casi. Vogliamo verificare questa ipotesi, testando la capacità di generalizzazione di un LLM anche con un trainset più contenuto.</p>
<p>Ma c'è di più. La scelta di un dataset bilanciato è di importanza critica. Immaginate di voler insegnare a un bambino il mondo animale. Se gli mostraste solo gatti, il bambino imparerebbe a riconoscere i gatti benissimo, ma avrebbe difficoltà con i cani o gli uccelli. Allo stesso modo, un dataset sbilanciato, dove alcune categorie (per esempio, certe emozioni o topic) sono sovra-rappresentate, porterebbe l'LLM a:</p>
<ul>
<li>
<p>Sovra-apprendere le categorie più frequenti, diventando un "esperto" solo su quelle.</p>
</li>
<li>
<p>Sotto-stimare o addirittura ignorare le categorie meno comuni, ma magari altrettanto importanti per il nostro scopo.</p>
</li>
</ul>
<p>Un trainset bilanciato assicura che il modello sia esposto a tutte le sfumature e varietà presenti nei dati, rendendolo più robusto e capace di generalizzare bene anche su osservazioni che non rientrano nelle categorie più comuni.</p>
<p>Vogliamo che il trainset rappresenti al meglio la ricchezza e la varietà del dataset completo, specialmente quando si tratta di emozioni (Label) e di varietà degli Embeddings (Umap10KMeans). Qui entra in gioco la logica di stratificazione.</p>
<p>Immaginate il vostro dataset come un grande cesto di frutta mista. Ci sono mele rosse, mele verdi, banane e magari qualche frutto esotico raro. Se prendessimo a caso 50 frutti, potremmo ritrovarci con tantissime mele rosse e nessuna banana o frutto esotico. Questo è ciò che succede con un campionamento puramente casuale: le categorie più abbondanti tendono a dominare, mentre quelle meno comuni vengono trascurate.</p>
<p>La nostra logica di stratificazione evita proprio questo squilibrio. Dividiamo il nostro "cesto di frutta" in tanti piccoli "scomparti", dove ogni scomparto è una combinazione unica di Label e di Embeddings (Umap10KMeans). Ognuno di questi scomparti costituisce un nostro strato di campionamento.</p>
<h1 id="perche-gemma3">Perchè Gemma3</h1>
<p>blabla blabla </p>
<p><img alt="Map" src="../assets/images/gemma3.png" /></p>
<h1 id="fine-tuning-a-small-llm">Fine-tuning a small LLM</h1>
<p>Il <span style="background-color: red;"><a href="https://github.com/Mahalanobis/Mahalanobis.io/blob/main/code/FineTuning_Gemma3_1B_v0.py">codice</a></span> implementa un processo di fine-tuning di un LLM, nello specifico <a href="https://huggingface.co/google/gemma-3-1b-it">Gemma 3 1b it</a>, specializzandosi nella classificazione delle emozioni. 
Le soluzioni principali utilizzate per rendere questo processo efficiente, soprattutto in termini di utilizzo della memoria (VRAM) e velocità, sono le seguenti:</p>
<p><img alt="Map" src="../assets/images/unsloth.png" /></p>
<ul>
<li><strong>Unsloth (e tecniche di Efficient Fine-tuning come QLoRA e LoRA)</strong>: <a href="https://unsloth.ai/">Unsloth</a> è una libreria che ottimizza il processo di fine-tuning degli LLM, rendendolo significativamente più veloce e meno esigente in termini di memoria rispetto alle implementazioni standard. Lo fa attraverso varie ottimizzazioni a basso livello. Come funziona nel codice:<ul>
<li>from unsloth import FastLanguageModel: Importa la classe FastLanguageModel che è la versione ottimizzata di Unsloth per caricare e gestire i modelli.</li>
<li>load_in_4bit=True: Questo parametro attiva la tecnica <a href="https://arxiv.org/abs/2305.14314">QLoRA (Quantized Low-Rank Adaptation)</a>. Invece di caricare l'intero modello in precisione floating point completa (es. FP16 o FP32), che richiederebbe molta VRAM, QLoRA lo quantizza a 4 bit. Questo riduce drasticamente l'impronta di memoria del modello base.</li>
<li>model = FastLanguageModel.get_peft_model(model, **LORA_CONFIG): Questo applica la tecnica <a href="https://arxiv.org/abs/2106.09685">LoRA (Low-Rank Adaptation)</a>. Invece di addestrare tutti i milioni o miliardi di parametri del modello, LoRA "congela" il modello base quantizzato e aggiunge solo un piccolo numero di "adattatori" (matrici a basso rango) che vengono addestrati. Questi adattatori sono molto più piccoli del modello completo, riducendo enormemente il numero di parametri addestrabili e quindi la VRAM e il tempo di calcolo necessari. La configurazione (LORA_CONFIG) definisce i parametri di LoRA, come r (rango delle matrici) e target_modules (quali parti del modello modificare).</li>
<li>optim="paged_adamw_8bit": Questo specifica un ottimizzatore "<em>paged</em>" che gestisce meglio la memoria. Parti dello stato dell'ottimizzatore possono essere spostate dalla VRAM alla RAM di sistema quando non sono immediatamente necessarie, liberando così preziosa VRAM per le operazioni di calcolo.</li>
<li>use_gradient_checkpointing=True: Questa tecnica sacrifica leggermente la velocità di addestramento per un notevole risparmio di VRAM. Durante il forward pass (calcolo delle predizioni), non tutte le attivazioni intermedie vengono memorizzate. Durante il backward pass (calcolo dei gradienti), le attivazioni necessarie vengono ricalcolate al volo, riducendo la memoria occupata.  </li>
</ul>
</li>
</ul>
<p><img alt="Map" src="../assets/images/hf_transformers.png" /></p>
<ul>
<li><strong>Hugging Face Transformers e TRL (Transformer Reinforcement Learning)</strong>: Librerie fondamentali nell'ecosistema di Hugging Face per lavorare con LLM. Transformers fornisce la struttura per caricare modelli, tokenizer e definire gli argomenti di addestramento (TrainingArguments). TRL è una libreria costruita su Transformers che fornisce strumenti specifici per il fine-tuning di LLM, in particolare per compiti come il Supervised Fine-tuning (SFT) e il Reinforcement Learning from Human Feedback (RLHF). Come funziona nel codice:<ul>
<li>TrainingArguments: Definisce tutti i parametri dell'addestramento, come la dimensione del batch (per_device_train_batch_size), i passi di accumulo del gradiente (gradient_accumulation_steps), il learning rate, il numero massimo di passi, e il salvataggio dei log.</li>
<li>SFTTrainer: È la classe del trainer fornita da TRL specificamente progettata per il Supervised Fine-tuning. Gestisce il ciclo di addestramento, l'applicazione del tokenizer, l'invio dei dati al modello e il calcolo dei gradienti. Semplifica notevolmente il codice necessario per l'addestramento.</li>
<li>tokenizer: Il tokenizer è essenziale per convertire il testo (le frasi e le etichette delle emozioni) in un formato numerico che il modello può comprendere e viceversa. Il codice lo carica insieme al modello.</li>
<li>dataset_text_field="text": Indica al SFTTrainer quale campo del dataset formattato contiene il testo da utilizzare per l'addestramento.  </li>
</ul>
</li>
</ul>
<p><img alt="Map" src="../assets/images/hf_datasets.png" /></p>
<ul>
<li><strong>Hugging Face Datasets</strong>: È una libreria efficiente per caricare, elaborare e gestire grandi dataset in modo performante, anche quando non stanno completamente in RAM. Come funziona nel codice:<ul>
<li>load_dataset("parquet", data_files={"train": DATASET_PATH}): Carica il dataset da un file Parquet, che è un formato di file colonnare efficiente per i dati tabellari.</li>
<li>.filter(lambda x: x["Trainset"] == 1): Permette di selezionare solo i campioni desiderati dal dataset in modo efficiente.</li>
<li>.train_test_split(test_size=0.1, seed=42): Suddivide il dataset in set di addestramento e validazione, essenziale per valutare le prestazioni del modello su dati non visti.</li>
<li>.map(formatting_func, batched=True): Applica una funzione di formattazione a tutti i campioni del dataset in modo "batchizzato" (elaborando più campioni alla volta), ottimizzando la velocità di pre-elaborazione.  </li>
</ul>
</li>
</ul>
<p><img alt="Map" src="../assets/images/VRAM.png" /></p>
<ul>
<li><strong>Monitoraggio VRAM Multi-thread</strong>: Permette di tenere traccia dell'utilizzo della memoria della GPU (VRAM) in tempo reale durante l'esecuzione dello script, inclusi i momenti di caricamento del modello e di addestramento. Questo è cruciale per diagnosticare problemi di "Out Of Memory" (OOM) o per capire come le ottimizzazioni influenzano il consumo di memoria. Come funziona nel codice:<ul>
<li>threading.Thread: Viene creato un thread separato (vram_monitor_thread) che si occupa esclusivamente di campionare periodicamente l'utilizzo della VRAM (get_vram_usage()) e di salvare i dati in una coda (queue).</li>
<li>torch.cuda.memory_allocated() e torch.cuda.memory_reserved(): Funzioni di PyTorch che restituiscono rispettivamente la memoria effettivamente allocata dal codice e la memoria totale riservata da PyTorch sulla GPU.</li>
<li>La visualizzazione finale con matplotlib.pyplot crea un grafico dell'andamento della VRAM nel tempo.  </li>
</ul>
</li>
</ul>
<p><img alt="Map" src="../assets/images/earlystopping.png" /></p>
<ul>
<li><strong>Callback Personalizzato per Early Stopping</strong>: L'addestramento di modelli di deeplearning può essere costoso. L'Early Stopping è una tecnica per fermare l'addestramento quando il modello smette di migliorare (o inizia a peggiorare) su una metrica specifica (in questo caso, la training loss). Questo previene l'overfitting e risparmia risorse computazionali. Come funziona nel codice:<ul>
<li>CustomEarlyStoppingCallback(TrainerCallback): Viene definita una classe che eredita da TrainerCallback di Hugging Face. Questo permette di "agganciarsi" a specifici eventi durante il ciclo di addestramento.</li>
<li>on_step_end: Questo metodo viene chiamato alla fine di ogni passo di addestramento. Il callback monitora la "loss" (perdita) dell'addestramento. Se la loss non diminuisce per un numero prestabilito di passi consecutivi (patience), il callback imposta un flag (control.should_training_stop = True) che segnala al Trainer di interrompere l'addestramento.</li>
</ul>
</li>
</ul>
<p><img alt="Map" src="../assets/images/ft_unsloth.png" /></p>
<p>L'intero processo di fine-tuning, a partire dalle 50K frasi e le rispettive emozioni che costituiscono il <em>trainset</em>, impiega poco più di 1000 secondi, ~15 minuti.</p>
<h2 id="vram">VRAM</h2>
<p><img alt="Map" src="../assets/images/ft_vram_usage.png" /></p>
<h2 id="training">Training</h2>
<p><img alt="Map" src="../assets/images/ft_training_loss.png" /></p></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script src="../js/bootstrap.bundle.min.js"></script>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js"></script>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script src="https://cdn.jsdelivr.net/npm/mathjax @3/es5/tex-mml-chtml.js"></script>
        <script src="../search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
