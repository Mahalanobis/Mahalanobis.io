---
title: "Fine-Tuning a small LLM (using a statistical approach)"
output:
  md_document:
    variant: markdown_github
    toc: true
    pandoc_args: ["--extract-media", "docs/assets/images"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Recentemente ho avuto il piacere di tenere una conferenza didattica nell'ambito del corso "_Analisi dei dati (data mining)_", tenuto dal prof. [Bruno Scarpa](https://homes.stat.unipd.it/brunoscarpa/), presso il [Dipartimento di Scienze Statistiche](https://www.stat.unipd.it/) a Padova. L'intervento verteva sull'evoluzione dell'**Intelligenza Artificiale (AI)** negli ultimi anni, _un percorso affascinante che ci ha portato dalle rappresentazioni lessicali come il Bag of Words alle architetture neurali avanzate basate sui Transformer_.

Trattandosi di una discussione ad alto livello, ho sentito il desiderio di integrare quell'intervento con esempi più pratici e più vicini all'esperienza di chi, come me, proviene da quello stesso percorso formativo. Questo ha portato alla nascita di questa serie di tutorial, pensata per costruire un ponte tra l'_AI Generativa_ e l'_AI Tradizionale_.

L'architrave di questo ponte è costituita dai problemi di _Supervised Classification_. 
Vedremo come, nel contesto dell'AI Generativa, questi problemi possano essere affrontati con il fine-tuning di un Large Language Model (LLM). Un'occasione unica per mettere a confronto i due mondi.

Un aspetto rilevante di questa comparazione sarà la misurazione dell'incertezza e dell'errore. 
Nel mondo dell'AI tradizionale siamo abituati a quantificare l'errore attraverso probabilità, intervalli di confidenza e metriche derivate dai logit. 
Vedremo che anche nel contesto degli LLM possiamo accedere ai logit e quindi trattare l'errore con la stessa familiarità e precisione a cui siamo abituati. 

L'aspetto pratico che guiderà lo sviluppo del codice utilizzato in questi tutorial sarà il focus sull'elaborazione su GPU, essenziale per la gestione efficiente di modelli complessi che richiedono un hardware specifico.
L'invito è sperimentare. Al di là delle complessità degli aspetti tecnici e metodologici è un mondo più accessibile di quanto uno possa pensare.

Ringrazio i colleghi Guglielmo Strumia e Marco Cozzolino per gli spunti e il supporto; questa serie è il frutto del lavoro di tutti noi. Grazie ancora.

